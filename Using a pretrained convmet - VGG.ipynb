{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recog- nition,” arXiv (2014), https://arxiv.org/abs/1409.1556\n",
    "\n",
    "There are two ways to use a pretrained network: *feature extraction* and *fine-tuning*\n",
    "\n",
    "## 1. Feature extraction\n",
    "\n",
    "ConvNets used for image classification comprise 2 parts: convolutional base and densely connected classifier. Feature extraction = taking the convolutional base of the previously trained network, running the data through it, and training a new classifier on top of the output. This is because the representations learned by the convolution base are more generic and more reusable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the VGG16 convolutional base\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                 input_shape = (150,150,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways to go from here \n",
    "- Running the conv base over your dataset, recording its output to a Numpy array on disk\n",
    "- Extending the model by adding Dense layers on top, and running the whole thing end to end on the input data. This allows data augmentation\n",
    "\n",
    "\n",
    "### Fast feature extraction without Data Augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/Users/anhpham/Projects/DLWP_Manning/Chapter5/Dogs-vs-Cats-small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count,4,4,512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size = (150,150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode = 'binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i*batch_size:(i+1)*batch_size]=features_batch\n",
    "        labels[i*batch_size:(i+1)*batch_size]=labels_batch\n",
    "        i += 1\n",
    "        if i*batch_size>=sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.5884 - acc: 0.6760 - val_loss: 0.4320 - val_acc: 0.8520\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.4225 - acc: 0.8080 - val_loss: 0.3630 - val_acc: 0.8500\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3516 - acc: 0.8485 - val_loss: 0.3207 - val_acc: 0.8750\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.3194 - acc: 0.8625 - val_loss: 0.2982 - val_acc: 0.8870\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2856 - acc: 0.8815 - val_loss: 0.2839 - val_acc: 0.8950\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2640 - acc: 0.8935 - val_loss: 0.2729 - val_acc: 0.8830\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2509 - acc: 0.8980 - val_loss: 0.2633 - val_acc: 0.8870\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2305 - acc: 0.9060 - val_loss: 0.2640 - val_acc: 0.8980\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2167 - acc: 0.9130 - val_loss: 0.2521 - val_acc: 0.8960\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.2089 - acc: 0.9205 - val_loss: 0.2500 - val_acc: 0.8970\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1990 - acc: 0.9215 - val_loss: 0.2451 - val_acc: 0.8990\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1842 - acc: 0.9315 - val_loss: 0.2420 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1769 - acc: 0.9355 - val_loss: 0.2407 - val_acc: 0.9050\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1702 - acc: 0.9450 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1657 - acc: 0.9405 - val_loss: 0.2365 - val_acc: 0.9060\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1540 - acc: 0.9460 - val_loss: 0.2482 - val_acc: 0.9010\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1504 - acc: 0.9495 - val_loss: 0.2419 - val_acc: 0.9000\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1423 - acc: 0.9500 - val_loss: 0.2369 - val_acc: 0.9050\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1432 - acc: 0.9480 - val_loss: 0.2418 - val_acc: 0.8970\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1370 - acc: 0.9505 - val_loss: 0.2336 - val_acc: 0.9040\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1299 - acc: 0.9570 - val_loss: 0.2375 - val_acc: 0.8990\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1191 - acc: 0.9620 - val_loss: 0.2382 - val_acc: 0.9020\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1152 - acc: 0.9635 - val_loss: 0.2472 - val_acc: 0.8980\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1132 - acc: 0.9665 - val_loss: 0.2394 - val_acc: 0.9000\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1117 - acc: 0.9630 - val_loss: 0.2417 - val_acc: 0.8990\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1054 - acc: 0.9645 - val_loss: 0.2460 - val_acc: 0.9010\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.1050 - acc: 0.9670 - val_loss: 0.2347 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1028 - acc: 0.9670 - val_loss: 0.2398 - val_acc: 0.9010\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0911 - acc: 0.9740 - val_loss: 0.2375 - val_acc: 0.9030\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 0.0891 - acc: 0.9740 - val_loss: 0.2385 - val_acc: 0.9050\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The extracted features are of shape (samples,4,4,512).\n",
    "These have to be flattened before being fed to the densely \n",
    "connected classifier\n",
    "'''\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000,4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))\n",
    "\n",
    "# Defining and training the densely connected classifier\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation = 'relu', input_dim=4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "              loss ='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=30, batch_size=20,\n",
    "                   validation_data = (validation_features, validation_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/I4QcdahQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181d898650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKQhBXcRkTSk4C4ikoYU3EVE0tD/ByEo99AxdScUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181dcc7790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc,'b', label = \"Validation acc\")\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Feature Extraction with Data Augmentation, since it is computationally expesinve -> use AWS GPU instance instead\n",
    "\n",
    "Models behave just like layers => add conv_base in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a densely connected classifier on top of the convolutional base\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before compiling and training the model: freeze the convolutional base to prevent their weights from being updated during training. If this step is not done, the represenations that were previously learned by the convolutional base will be modified during training. \n",
    "\n",
    "In Keras, this can be done by setting the network *trainable* attribute to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the model end to end with a frozen convolutional base\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # validation data shouldn't be augmeneted\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150,150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150,150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "             metrics = ['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Fine Tuning\n",
    "\n",
    "This is complementary to feature extraction. Fine tuning consists of unfreezing a few of the top layers of the frozen model base used for feature extraction and jointly training both the newly added part of the model and these top layers. It is a must to freeze the convolution base of VGG16 in order to train a randomly initialized classifier on top. And it's only possible to fine-tune the top layers of the convolutional base once the classifier on top has already been trained. \n",
    "\n",
    "The steps for fine-tuning a network;\n",
    "1. Add your custom network on top of an already-trained base network\n",
    "2. Freeze your base net-work\n",
    "3. Train the part you added\n",
    "4. Unfreeze some layers in the base network\n",
    "5. Jointly train both these layers and the part you added\n",
    "\n",
    "The first 3 steps were done with feature extraction\n",
    "\n",
    "\n",
    "Note\n",
    "- It's more useful to fine-tune the more specialized features, because these are the ones that need to be repurposed on your new problem. There would be fast-decreasing returns in fine-tuning lower layers\n",
    "- More parameters = higher risk of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7421916f6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m train_generator = train_datagen.flow_from_directory(\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Freezing all layers up to a specific one\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Fine-tuning the model using RMSprop with a low learning rate \n",
    "# to avoid harming the represenations with too large updates\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr=1e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=100,\n",
    "            epochs =100,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smoothing the plots by replacing every loss and accuracy with exponential moving averages of these quantities\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "def smooth_curve(points, factor = 0.8):\n",
    "    smoothed_points =[]\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous*factor + point*(1-factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(acc),'bo',labels ='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_acc),'b',labels = 'Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "- Convnets are the best type of machine-learning models for computer-vision tasks. It's possible to train from scratch even on a very small dataset with decent results\n",
    "- On a small dataset, overfitting will be the main issue. Data augmentation is a powerful way to fight overfitting when you're working wiht image data\n",
    "- It's easy to reuse an existing convnet on a new dataset via feature extraction. This is a valuabel technique for working with small image datasets.\n",
    "- As a complement to feature extraction, you can use fine-tuning, which adapts to a new problem some of the represenations previously learned by an existing model. This pushes performance a bit further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
