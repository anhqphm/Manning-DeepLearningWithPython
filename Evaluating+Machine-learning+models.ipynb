{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hold-out validation\n",
    "\n",
    "This is the simplest version. However if little data is availale, then your validation and test sets may contain too few samples to be statistically representative of the data at hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# At this point, you can tune your model, retrain it, evaluate it and tune it again\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data, validation_data]))\n",
    "test_score = model.evaluate(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-fold validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_validation_samples = len(data)//k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples*fold:num_validation_samples*(fold+1)]\n",
    "    training_data = data[:num_validation_samples*fold]+data[num_validation_samples*(fold+1):]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "    \n",
    "    validation_score = np.average(validation_scores)\n",
    "    \n",
    "    model = get_model()\n",
    "    model.train(data)\n",
    "    test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated K-fold validation with shuffling\n",
    "\n",
    "This is the situation in which relatively little data is available and you need to evaluate your model as precisely as possible. This is extremely helpful in Kaggle competitions. It consists of applying K-fold validation multiple times, shuffling the data every time before splitting it in K ways. The final score is the average of the scores obtained at each run of K-fold validation. \n",
    "Note that this ends up in training and evaluateing P x K models (where P is the number of iterations), which can be very expensive.\n",
    "\n",
    "## Things to pay attention to\n",
    "- Data representativeness: both training set and test set should bre representative of the data. Should randomly shuffle data before splitting it into training and test sets.\n",
    "- The arrow of time: for prediction of the future given the past, data should not be randomly shuffled to avoid temporal leak. Should always make sure all data in your test set is posterior to the data in training set. \n",
    "- Redundancy in your data: Make sure your training set and validation set are disjoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
